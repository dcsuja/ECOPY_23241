{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de9d9737616514b8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Az eredményeket mentsd a src/weekly modul-ba weekly_test_6.py néven"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9789db8f0fbd7ec",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Használható modulok: pathlib, pandas, typing, str, statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfea6e648868022e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datalib = Path.cwd().parent.joinpath('data')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0b5dd4685315eda"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d26aec7b4e97407",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1., Olvasd be a data mappa sp500.parquet nevű fájlját egy DataFrame-be. A betöltéshez használt engine paramétere legyen fastparquet\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "File \u001B[0;32m~/Documents/GitHub/ECOPY_23241/venv/lib/python3.10/site-packages/pandas/compat/_optional.py:132\u001B[0m, in \u001B[0;36mimport_optional_dependency\u001B[0;34m(name, extra, errors, min_version)\u001B[0m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 132\u001B[0m     module \u001B[38;5;241m=\u001B[39m \u001B[43mimportlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/importlib/__init__.py:126\u001B[0m, in \u001B[0;36mimport_module\u001B[0;34m(name, package)\u001B[0m\n\u001B[1;32m    125\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m--> 126\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1050\u001B[0m, in \u001B[0;36m_gcd_import\u001B[0;34m(name, package, level)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1027\u001B[0m, in \u001B[0;36m_find_and_load\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1004\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[0;34m(name, import_)\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'fastparquet'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_parquet\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m../data/sp500.parquet\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfastparquet\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(df)\n",
      "File \u001B[0;32m~/Documents/GitHub/ECOPY_23241/venv/lib/python3.10/site-packages/pandas/io/parquet.py:654\u001B[0m, in \u001B[0;36mread_parquet\u001B[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001B[0m\n\u001B[1;32m    501\u001B[0m \u001B[38;5;129m@doc\u001B[39m(storage_options\u001B[38;5;241m=\u001B[39m_shared_docs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstorage_options\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m    502\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mread_parquet\u001B[39m(\n\u001B[1;32m    503\u001B[0m     path: FilePath \u001B[38;5;241m|\u001B[39m ReadBuffer[\u001B[38;5;28mbytes\u001B[39m],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    511\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    512\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame:\n\u001B[1;32m    513\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    514\u001B[0m \u001B[38;5;124;03m    Load a parquet object from the file path, returning a DataFrame.\u001B[39;00m\n\u001B[1;32m    515\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    651\u001B[0m \u001B[38;5;124;03m    1    4    9\u001B[39;00m\n\u001B[1;32m    652\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 654\u001B[0m     impl \u001B[38;5;241m=\u001B[39m \u001B[43mget_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    656\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m use_nullable_dtypes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mno_default:\n\u001B[1;32m    657\u001B[0m         msg \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    658\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe argument \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124muse_nullable_dtypes\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is deprecated and will be removed \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    659\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124min a future version.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    660\u001B[0m         )\n",
      "File \u001B[0;32m~/Documents/GitHub/ECOPY_23241/venv/lib/python3.10/site-packages/pandas/io/parquet.py:79\u001B[0m, in \u001B[0;36mget_engine\u001B[0;34m(engine)\u001B[0m\n\u001B[1;32m     77\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m PyArrowImpl()\n\u001B[1;32m     78\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m engine \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfastparquet\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m---> 79\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mFastParquetImpl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     81\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mengine must be one of \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpyarrow\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfastparquet\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/GitHub/ECOPY_23241/venv/lib/python3.10/site-packages/pandas/io/parquet.py:298\u001B[0m, in \u001B[0;36mFastParquetImpl.__init__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    295\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    296\u001B[0m     \u001B[38;5;66;03m# since pandas is a dependency of fastparquet\u001B[39;00m\n\u001B[1;32m    297\u001B[0m     \u001B[38;5;66;03m# we need to import on first use\u001B[39;00m\n\u001B[0;32m--> 298\u001B[0m     fastparquet \u001B[38;5;241m=\u001B[39m \u001B[43mimport_optional_dependency\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    299\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfastparquet\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfastparquet is required for parquet support.\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[1;32m    300\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    301\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi \u001B[38;5;241m=\u001B[39m fastparquet\n",
      "File \u001B[0;32m~/Documents/GitHub/ECOPY_23241/venv/lib/python3.10/site-packages/pandas/compat/_optional.py:135\u001B[0m, in \u001B[0;36mimport_optional_dependency\u001B[0;34m(name, extra, errors, min_version)\u001B[0m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n\u001B[1;32m    134\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 135\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(msg)\n\u001B[1;32m    136\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001B[39;00m\n",
      "\u001B[0;31mImportError\u001B[0m: Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('../data/sp500.parquet', engine='fastparquet')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T18:12:28.414994Z",
     "start_time": "2023-10-25T18:12:27.603469Z"
    }
   },
   "id": "43f685fc4780d23a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2., Olvasd be az ff_factors.parquet fájlt egy DataFrame-be. A betöltéshez használt engine paramétere legyen fastparquet\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d42ee754b557dcef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ff_factors_df = pd.read_parquet('ff_factors.parquet', engine='fastparquet')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c757103536fa82f7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79c977da040d844",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "3., Kapcsold össze a két DataFrame-t egy új DataFrame-be. Az összekapcsolás módja, hogy a hozam adatokra balról kapcsoljuk rá a factor adatokat a 'Date' elsődleges kulcs alapján.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Joined data](../resources/weekly6/joined_data.jpg)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf54c6765186a23e"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m merged_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mmerge(\u001B[43mdf\u001B[49m, ff_factors_df, on\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDate\u001B[39m\u001B[38;5;124m'\u001B[39m, how\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mleft\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(merged_df\u001B[38;5;241m.\u001B[39mhead())\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(df, ff_factors_df, on='Date', how='left')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T17:24:54.695640Z",
     "start_time": "2023-10-25T17:24:54.644570Z"
    }
   },
   "id": "34bc40351687c32"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd10fafbf699543d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "4., Készíts egy új 'Excess Return' nevű oszlopot, ami a havi hozamok és a kockázat mentes hozam (RF) különbsége\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_df['Excess Return'] = merged_df['Return'] - merged_df['RF']\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdc8822a72cb19f6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "5., Rendezd sorba dátum szerint az adatokat, majd generálj egy új oszlopot ('ex_ret_1'), amely minden ticker ('Symbol') esetén 1-el eltolja az Excess Return értékeit olyan módon, hogy minden sorban szerepeljen a következő időszaki Excess Return érték. \n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6af93a4a3c53398"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![new column](../resources/weekly6/ex_ret_1.jpg)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6be746933376572"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmerged_df\u001B[49m\u001B[38;5;241m.\u001B[39msort_values(by\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDate\u001B[39m\u001B[38;5;124m'\u001B[39m, inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      3\u001B[0m merged_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mex_ret_1\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m merged_df\u001B[38;5;241m.\u001B[39mgroupby(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSymbol\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExcess Return\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshift(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(merged_df\u001B[38;5;241m.\u001B[39mhead())\n",
      "\u001B[0;31mNameError\u001B[0m: name 'merged_df' is not defined"
     ]
    }
   ],
   "source": [
    "merged_df.sort_values(by='Date', inplace=True)\n",
    "\n",
    "merged_df['ex_ret_1'] = merged_df.groupby('Symbol')['Excess Return'].shift(-1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T17:30:14.857560Z",
     "start_time": "2023-10-25T17:30:14.696661Z"
    }
   },
   "id": "2285003630c207d3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fd1aa0c59afb47",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "6., A meglévő adathalmazt írd felül olyan módon, hogy egyszer törlöd az össze olyan sort, amely az 'ex_ret_1' oszlopban hiányos, majd ezt követően, törlöd az összes olyan sort, ami a 'HML' oszlopban hiányos\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f333cdfad16d315f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4637c401e0e6352c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A meglévő adatokból válaszd ki a Amazon részvényhez tartozó sorokat (AMZN) és töröld a tickereket tartalmazó oszlopot\n",
    "\n",
    "7., Készíts egy új LinearRegressionSM elnevezésű osztályt. Definiáld benne a __init__ nevű függvényt, amely bemenetként 2 DataDrame-t kap amelyeket ments le a left_hand_side és right_hand_side elnevezésű változókba. Az egyik DataFrame fogja tartalmazni a következő hónap többlet hozamait (left_hand_side), a másik a piaci hozamokat (Mkt-RF), az SMB és a HML értékeket (right_hand_side)\n",
    "\n",
    "\n",
    "8., Egésztsd ki az osztályt egy fit metódussal, ami meghívja a statsmodels segítségével OLS alapon becsült modellt illeszt az osztály adattagjaira. A becslésből visszakapott modellt mentse le az osztály _model adattagjába. Figyelj oda, hogy a regresszió futtatása során konstans (alfa / béta_0) is szerepeljen a predictor változók között.\n",
    "\n",
    "\n",
    "\n",
    "9., Egészítsd ki az osztályt egy get_params metódussal, ami visszaadja a becsült modellt béta paramétereinek értékeit. A visszakapott pandas Series típusú adatban az oszlop neve legyen 'Beta coefficients'\n",
    "\n",
    "\n",
    "\n",
    "10., Egészítsd ki az osztályt egy get_pvalues metódussal, ami visszaadja a becsült modell paraméterekhez tartozó p értékeket. A visszakapott pandas Series típusú adatban az oszlop neve legyen: P-values for the corresponding coefficients\n",
    "\n",
    "\n",
    "\n",
    "11., Egészítsd ki az osztályt egy get_wald_test_result metódussal, ami visszaadja a bemeneti restrikciós mátrix alapján számolt F és p értékeket. A visszatérési típus string legyen, a visszaadandó szöveg: F-value: fvalue, p-value: pvalue, ahol az fvalue és pvalue helyére 3 tizedesjegyre kerekítve adja meg a hozzájuk tartozó értékeket.\n",
    "\n",
    "\n",
    "\n",
    "12., Egészítse ki az osztályt egy get_model_goodness_values metódussal, ami visszadja a módosított R-négyzet, az Akaike és a Bayes információs kritériumok értékét. A visszatérési típus string legyen, a visszaadandó szöveg: Adjusted R-squared: ars, Akaike IC: ak, Bayes IC: by, ahol ars, ak és by helyére 3 tizedesjegyre kerekítve adja meg a hozzájuk tartozó értékeket.\n",
    "\n",
    "\n",
    "\n",
    "A létrehozott osztályt és a hozzátartozó metódusokat mentsd le a src.linear_regression mappába, a LinearRegressions.py fájlba.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "632e9b84be1a75ef"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
